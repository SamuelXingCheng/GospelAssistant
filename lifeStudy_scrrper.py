import requests
from bs4 import BeautifulSoup
import json
import os
import time

# è¨­å®šå„²å­˜ JSON çš„è³‡æ–™å¤¾
JSON_FOLDER = "lsm_lifestudy_json"
os.makedirs(JSON_FOLDER, exist_ok=True)

def get_lifestudy_content(url):
    """ çˆ¬å–æŒ‡å®šçš„ç”Ÿå‘½è®€ç¶“ç« ç¯€ """
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    response.encoding = "utf-8"
    soup = BeautifulSoup(response.text, "html.parser")
    
    # æ‰¾åˆ°ä¸»æ–‡å…§å®¹æ‰€åœ¨çš„å€åŸŸ
    content_div = soup.find("div", class_="ls-text")
    
    if not content_div:
        print(f"âŒ ç„¡æ³•æ‰¾åˆ°ä¸»æ–‡å…§å®¹: {url}")
        return None
    
    # æ“·å–ä¸»æ–‡å…§å®¹
    paragraphs = content_div.find_all("p")
    content_text = "\n".join([p.get_text(strip=True) for p in paragraphs])
    
    # çµ„åˆ JSON
    data = {
        "content": content_text
    }
    
    # å„²å­˜ JSON
    filename = url.split("/")[-1].replace(".html", "") + ".json"
    json_path = os.path.join(JSON_FOLDER, filename)
    with open(json_path, "w", encoding="utf-8") as file:
        json.dump(data, file, indent=4, ensure_ascii=False)
    
    print(f"ğŸ“‚ å·²å„²å­˜: {json_path}")
    return data

def scrape_lifestudy():
    """ è®“ä½¿ç”¨è€…è¼¸å…¥ç¶²å€ä¾†çˆ¬å–ç”Ÿå‘½è®€ç¶“å…§å®¹ """
    while True:
        url = input("\nè«‹è¼¸å…¥ç”Ÿå‘½è®€ç¶“ç¶²å€ (æˆ–è¼¸å…¥ 'exit' é›¢é–‹)ï¼š").strip()
        if url.lower() == "exit":
            break
        if not url.startswith("https://www.lsmchinese.org/lifestudy/"):
            print("âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„ç”Ÿå‘½è®€ç¶“ç¶²å€ï¼")
            continue
        get_lifestudy_content(url)
        time.sleep(1)  # é¿å…éåº¦è«‹æ±‚

if __name__ == "__main__":
    print("\nğŸ“– ç”Ÿå‘½è®€ç¶“çˆ¬å–å·¥å…· ğŸ“–")
    scrape_lifestudy()
